---
title: "domagoj_part_slide_presentation"
author: "Domagoj Korais"
date: "June 26, 2018"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cache  = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)

```


## Average root mean squared error


```{r amazon training size determination}
library(tidyverse)
#import dati calcolati altro pc con m=10 mm=10
super_avg=readRDS("~/0dssc/smds/statMethodsProject/computed_results/risultati_run_amazon_3h_nonliperdere.rds")
m=10
mm=10
#valori medi e deviazione standard dalla lista
media_rmse=data.frame(media=1:m)
sd_rmse = data.frame(sd=1:m)
training = data.frame(training = 1:m)
for (i in 1:m){
media_rmse[i,]=mean(super_avg[[i]]$avg)
sd_rmse[i,]=sd(super_avg[[i]]$avg)/mm^(1/2)
training[i,]=round(mean(super_avg[[i]]$training))
}
results=data.frame(training=training,media=media_rmse,sd=sd_rmse)


##plotting results
ggplot(results,aes(training,media))+
  geom_linerange(aes(ymin=media-sd, ymax=media+sd)) +
  geom_line()+
  labs(
  title="Avg. Root Mean Squared Error by number of elements in training set",
  subtitle=paste("Total number of texts:10000,10 run for each training value" ),
  caption="Dataset: Amazon ratings in section CDs and Vinyls. Subset with 2000 elements for each class")+
  scale_color_brewer(palette="Set2")+
  theme_minimal()
  
```

```{r import dataset}
#Importing data
library(tidyverse)
#   rename(rating=overall)
# saveRDS(reviews, "../dataset/amazon_CDs_and_vinyl.rds")
reviews=readRDS("~/0dssc/smds/statMethodsProject/dataset/amazon_CDs_and_vinyl.rds")
#contiamo le parole nei testi, dirty trick, conto gli spazi e aggiungo 1
reviews=reviews%>%
  mutate(number_words= (str_count(reviewText,pattern = " ")+1) )
#class distribution plot----
```



##Ratings count

```{r plot distribution ratings}
plot_distribution_ratings=function(reviews){
classes=reviews%>%
  select(rating)%>%
  group_by(rating)%>%
  summarise(total=n())%>%
  mutate(percentage=total/sum(total))

p=ggplot(classes,aes(rating,total,fill=as.factor(rating)))+
  geom_col()+
  labs(fill="Rating",
       title=" Ratings count",
       subtitle=" Dataset: Amazon CDs and vinyl",
       caption="Source: University of California, San Diego")+
  xlab("Rating")+
  ylab("Total count")+
  theme_minimal()
return(p)
}

plot_distribution_ratings(reviews)

```

##Distribution number of words

```{r Distribution number of words}

#plot dei risultati
ggplot(reviews,aes(number_words))+
  geom_histogram()+
  ggtitle(" words count")+
  xlim(0, 1000)+
  theme_minimal()
```


##Distribution number of words for low values

```{r Distribution number of words low count}

#plot dei risultati
ggplot(reviews,aes(number_words))+
  geom_histogram()+
  ggtitle(" words count")+
  xlim(0, 50)+
  theme_minimal()
```


##Relation between number of words and ratings

```{r number of words}


#check correlation length-rating----
reviews%>%
  filter( number_words<=400)%>%
ggplot(aes(x=as.factor(rating),y=number_words))+
  geom_boxplot()+
  labs(title="Relation between number of words and rating",
       subtitle=" Dataset: Amazon CDs and vinyl, filtered by number of words < 400",
       caption="Source: University of California, San Diego")+
  ylab("Number of words")+
  xlab("Rating")+
  theme_minimal()

```



## extra corte

```{r  frasi extra corte}
results=readRDS("../computed_results/results_extra_corte_1_15_cd.rds")
    ################plotting mod no bootstrap

    valori_fit = results$est.CSMF
    valori_veri = results$true.CSMF
    #sd_fit = results$CSMF.se
    #converto in dataframe
    valori_fit = as_tibble(as.list(valori_fit))
    valori_veri = as_tibble(as.list(valori_veri))
    #sd_fit = as_tibble(as.list(sd_fit))
    valori_plot=gather(valori_fit,type)
    valori_plot_veri=gather(valori_veri,type)
    #valori_sd=gather(sd_fit,type)
    #typeof(results$est.CSMF)
   
    #valori_sd
    valori_tot=inner_join(valori_plot,valori_plot_veri,by="type",suffix=c(".est",".real"))
    #valori_tot=inner_join(valori_tot,valori_sd)
    #valori_tot

    p=ggplot(data=valori_tot,aes(x=value.real,y=value.est,label = value.est))+
      geom_point(aes(color=type))+
    #  geom_linerange(aes(ymin=value.est-value, ymax=value.est+value,color=type)) +
     # ggtitle(" Computed vs fitted values for Amazon music dataset, frasi corte")+
      ggplot2::labs(
        title = "Computed vs fitted values, number of words <=15",
        subtitle = paste("total number of elements:",9898,",","of which training:",1000))+
      # geom_smooth(method=lm)+
      xlab("Real value")+
      ylab("Computed value")+
      theme_minimal()+
      geom_abline(slope = 1,intercept = 0)

    plot(p)
    ############################
```



##Frasi corte
```{r  frasi  corte}
results=readRDS("../computed_results/results_corte_16_50_cd.rds")
    ################plotting mod no bootstrap

    valori_fit = results$est.CSMF
    valori_veri = results$true.CSMF
    #sd_fit = results$CSMF.se
    #converto in dataframe
    valori_fit = as_tibble(as.list(valori_fit))
    valori_veri = as_tibble(as.list(valori_veri))
    #sd_fit = as_tibble(as.list(sd_fit))
    valori_plot=gather(valori_fit,type)
    valori_plot_veri=gather(valori_veri,type)
    #valori_sd=gather(sd_fit,type)
    #typeof(results$est.CSMF)
    
    #valori_sd
    valori_tot=inner_join(valori_plot,valori_plot_veri,by="type",suffix=c(".est",".real"))
    #valori_tot=inner_join(valori_tot,valori_sd)
    #valori_tot

    p=ggplot(data=valori_tot,aes(x=value.real,y=value.est,label = value.est))+
      geom_point(aes(color=type))+
    #  geom_linerange(aes(ymin=value.est-value, ymax=value.est+value,color=type)) +
     # ggtitle(" Computed vs fitted values for Amazon music dataset, frasi corte")+
      ggplot2::labs(
        title = "Computed vs fitted values, number of words <=50 e >=16",
        subtitle = paste("total number of elements:",9898,",","of which training:",1000))+
      # geom_smooth(method=lm)+
      xlab("Real value")+
      ylab("Computed value")+
      theme_minimal()+
      geom_abline(slope = 1,intercept = 0)

    plot(p)
    ############################
```


##Frasi lunghe
```{r  frasi lunghe}
results=readRDS("../computed_results/results_lunghe_51_200_cd.rds")
    ################plotting mod no bootstrap

    valori_fit = results$est.CSMF
    valori_veri = results$true.CSMF
    #sd_fit = results$CSMF.se
    #converto in dataframe
    valori_fit = as_tibble(as.list(valori_fit))
    valori_veri = as_tibble(as.list(valori_veri))
    #sd_fit = as_tibble(as.list(sd_fit))
    valori_plot=gather(valori_fit,type)
    valori_plot_veri=gather(valori_veri,type)
    #valori_sd=gather(sd_fit,type)
   
    valori_tot=inner_join(valori_plot,valori_plot_veri,by="type",suffix=c(".est",".real"))
    #valori_tot=inner_join(valori_tot,valori_sd)
    #valori_tot

    p=ggplot(data=valori_tot,aes(x=value.real,y=value.est,label = value.est))+
      geom_point(aes(color=type))+
    #  geom_linerange(aes(ymin=value.est-value, ymax=value.est+value,color=type)) +
     # ggtitle(" Computed vs fitted values for Amazon music dataset, frasi corte")+
      ggplot2::labs(
        title = "Computed vs fitted values, number of words <=200 e >=51",
        subtitle = paste("total number of elements:",10000,",","of which training:",1000))+
      # geom_smooth(method=lm)+
      xlab("Real value")+
      ylab("Computed value")+
      theme_minimal()+
      geom_abline(slope = 1,intercept = 0)

    plot(p)
    ############################
```


##Numero di tweet raccolti

```{r "top 20 Hashtag analysis"}
#hashtag study

#tidying dataset for lexical analysis
library(tidyverse)
library(rtweet)

library(gridExtra)

library(tidytext)
library(widyr)
library(igraph)
library(ggraph)
#--------------------------------------------------------------------------------------------Hashtag
#Tidy for hashtag study
dataset=readRDS("/home/doma/0dssc/data_managment/esame_finale/data/FINAL_DATA_DEFINITIVO/reduced_tweet_no_duplicati_stripped_text_separated.RDS")
#only italian language tweets
dataset=dataset%>%filter(lang=="it")





# remove punctuation, convert to lowercase.
dataset_clean <- dataset %>%
  select(hashtags) %>%
  unnest_tokens(word, hashtags)
#put in original dataframe
dataset$hashtags=dataset_clean$word

a=dataset_clean %>%
  count(word, sort = TRUE)




#plot the top 20 HASHTAGS
dataset_clean %>%
  count(word, sort = TRUE) %>%
  
  top_n(20+1) %>%
  filter(!is.na(word))%>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = word, y = n)) +
  geom_col(aes(alpha=n),show.legend =FALSE) +
  xlab(NULL) +
  coord_flip() +
  labs(x = "Hashtags",
       y = "Count",
       title = " Top 20 hashtags by count")+
  ggplot2::theme_minimal()

```

##Distro parole
```{r distro parole}
#plot dei risultati
megatrain=readRDS("../computed_results/distro_parole_tweets.rds")


megatrain%>%
  filter(number_words<100)%>%
ggplot(aes(number_words))+
  geom_histogram(bins=50)+
  ggtitle(" words count")+
  theme_minimal()
```

##Andamento temporale tweets

```{r "Hashtag analysis zoom"}

#hashtag study

#tidying dataset for lexical analysis
library(tidyverse)
library(rtweet)

library(gridExtra)

library(tidytext)
library(widyr)
library(igraph)
library(ggraph)
#--------------------------------------------------------------------------------------------Hashtag
#Tidy for hashtag study
dataset=readRDS("/home/doma/0dssc/data_managment/esame_finale/data/FINAL_DATA_DEFINITIVO/reduced_tweet_no_duplicati_stripped_text_separated.RDS")
#only italian language tweets
dataset=dataset%>%filter(lang=="it")

TIMEFRAME=data.frame(begin=as.POSIXct("2018-05-27 17:15:21", tz = "GMT"),end=as.POSIXct("2018-05-27 18:57:37", tz = "GMT"))

#zoom on hot time
p4=dataset%>%
  #filter(has_top_hashtag==TRUE)%>%
    filter(hashtags=="iostoconmattarella" | hashtags=="mattarelladimettiti" | hashtags=="impeachment" 
           | hashtags=="impeachmentmattarella" )%>%

  group_by(hashtags,is_retweet)%>%
   filter ( created_at >= as.POSIXct("2018-05-27 16:00:00",tz = "GMT") & created_at <= as.POSIXct("2018-05-28 00:00:00",tz = "GMT") ) %>%
  ts_plot( "5 minutes") +
  ggplot2::theme_minimal() +
  ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) +
  ggplot2::labs(
    x = NULL,
    y = NULL,
    title = "Frequency  Tweets statuses for period 16:00-24:00 27/05/2018",
    subtitle = "Twitter status (tweet) counts aggregated using five-minutes intervals",
    caption = "\nSource: Data collected from Twitter's REST API via rtweet",
    linetype="Retweet?",
    colour = " Hashtags"
  )  +
    geom_rect(data = TIMEFRAME,
                aes(xmin = as.POSIXct(begin,tz = "GMT"), xmax =as.POSIXct( end,tz = "GMT"), ymin = -Inf, ymax = +Inf),
                inherit.aes = FALSE, fill = "red", alpha = 0.1)
                
                
                p4
```


##Prova coi Tweet per verificare 

```{r}

mattarella1=readRDS("../computed_results/tweet_sentiment_test.rds")
valori_tot=mattarella1
valori_tot1=valori_tot
valori_tot1$type[valori_tot1$type==0] <- "Contra"
valori_tot1$type[valori_tot1$type==1] <- "Pro"
p=ggplot(data=valori_tot1,aes(x=value.real,y=value.est,label = value.est))+
  geom_point(aes(color=type))+
  #  geom_linerange(aes(ymin=value.est-value, ymax=value.est+value,color=type)) +
  # ggtitle(" Computed vs fitted values for Amazon music dataset, frasi corte")+
  ggplot2::labs(
    title = "Computed vs fitted values for Twitter dataset",
    subtitle = paste("total number of elements:",27754,",","of which training:",1000),
    caption = "Tweets downloaded usind R package Rtweet"  )+
  # geom_smooth(method=lm)+
  xlab("Real value")+
  ylab("Computed value")+
  theme_minimal()+
  geom_abline(slope = 1,intercept = 0)

plot(p)

```

##Mattarella sentiment

```{r Mattarella}
mattarella1=readRDS("../computed_results/tweet_mattarella_sentiment.rds")
valori_tot=mattarella1
valori_tot1=valori_tot
valori_tot1$type[valori_tot1$type==0] <- "Contra"
valori_tot1$type[valori_tot1$type==1] <- "Pro"

ggplot(valori_tot1,aes(y=value.est,x=type,fill=type))+
  labs(title="Pro e Contra Mattarella",
       subtitle= "From tweets with hashtag Mattarella",
       x="Sentiment",
       y="Percentage",
       caption="Tweets gathered using R library Rtweet for the period around May 27")+
  geom_col()+
  theme_minimal()+
  guides(fill=FALSE)

```

##Frasi 